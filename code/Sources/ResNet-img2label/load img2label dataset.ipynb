{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load img2label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/notebooks/language2motion.gt/code\")\n",
      "\t\tBatcher\n",
      "\t\tModelSupport\n",
      "\t\tDatasets\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmp0z2rkk8r/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "// %install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"tensorflow-0.8\"))' Batcher ModelSupport Datasets\n",
    "%install '.package(path: \"/notebooks/language2motion.gt/code\")' Batcher ModelSupport Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Datasets\n",
    "import ImageClassificationModels\n",
    "import TensorFlow\n",
    "\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import TensorFlow\n",
    "import Batcher\n",
    "import Datasets\n",
    "import TensorPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ImageClassificationDataset\n",
    "import DatasetUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "func loadCIFARFile(named name: String, in directory: URL, normalizing: Bool = true) -> [TensorPair<Float, Int32>] {\n",
    "    let path = directory.appendingPathComponent(\"cifar-10-batches-bin/\\(name)\").path\n",
    "\n",
    "    let imageCount = 200 //10000\n",
    "    print(imageCount)\n",
    "    guard let fileContents = try? Data(contentsOf: URL(fileURLWithPath: path)) else {\n",
    "        printError(\"Could not read dataset file: \\(name)\")\n",
    "        exit(-1)\n",
    "    }\n",
    "    guard fileContents.count == 30_730_000 else {\n",
    "        printError(\n",
    "            \"Dataset file \\(name) should have 30730000 bytes, instead had \\(fileContents.count)\")\n",
    "        exit(-1)\n",
    "    }\n",
    "\n",
    "    var bytes: [UInt8] = []\n",
    "    var labels: [Int64] = []\n",
    "\n",
    "    let imageByteSize = 3073\n",
    "    for imageIndex in 0..<imageCount {\n",
    "        let baseAddress = imageIndex * imageByteSize\n",
    "        labels.append(Int64(fileContents[baseAddress]))\n",
    "        bytes.append(contentsOf: fileContents[(baseAddress + 1)..<(baseAddress + 3073)])\n",
    "    }\n",
    "\n",
    "    let labelTensor = Tensor<Int64>(shape: [imageCount], scalars: labels)\n",
    "    let images = Tensor<UInt8>(shape: [imageCount, 3, 32, 32], scalars: bytes)\n",
    "\n",
    "    // Transpose from the CIFAR-provided N(CHW) to TF's default NHWC.\n",
    "    var imageTensor = Tensor<Float>(images.transposed(permutation: [0, 2, 3, 1]))\n",
    "\n",
    "    // The value of mean and std were calculated with the following Swift code:\n",
    "    // ```\n",
    "    // import TensorFlow\n",
    "    // import Datasets\n",
    "    // import Foundation\n",
    "    // let urlString = \"https://storage.googleapis.com/s4tf-hosted-binaries/datasets/CIFAR10/cifar-10-binary.tar.gz\"\n",
    "    // let cifar = CIFAR10(batchSize: 50000,\n",
    "    //                     remoteBinaryArchiveLocation: URL(string: urlString)!,\n",
    "    //                     normalizing: false)\n",
    "    // for batch in cifar.training.sequenced() {\n",
    "    //     let images = Tensor<Double>(batch.first) / 255.0\n",
    "    //     let mom = images.moments(squeezingAxes: [0,1,2])\n",
    "    //     print(\"mean: \\(mom.mean) std: \\(sqrt(mom.variance))\")\n",
    "    // }\n",
    "    // ```\n",
    "    if normalizing {\n",
    "        let mean = Tensor<Float>(\n",
    "                [0.4913996898,\n",
    "                 0.4821584196,\n",
    "                 0.4465309242])\n",
    "        let std = Tensor<Float>(\n",
    "                [0.2470322324,\n",
    "                 0.2434851280,\n",
    "                 0.2615878417])\n",
    "        imageTensor = ((imageTensor / 255.0) - mean) / std\n",
    "    }\n",
    "    \n",
    "    return (0..<imageCount).map { TensorPair(first: imageTensor[$0], second: Tensor<Int32>(labelTensor[$0])) }\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "func loadCIFARTrainingFiles(localStorageDirectory: URL, normalizing: Bool = true) -> [TensorPair<Float, Int32>] {\n",
    "    let data = (1..<6).map {\n",
    "        loadCIFARFile(named: \"data_batch_\\($0).bin\", in: localStorageDirectory, normalizing: normalizing)\n",
    "    }\n",
    "    return data.reduce([], +)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func loadCIFARTestFile(localStorageDirectory: URL, normalizing: Bool = true) -> [TensorPair<Float, Int32>] {\n",
    "    return loadCIFARFile(named: \"test_batch.bin\", in: localStorageDirectory, normalizing: normalizing)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func downloadCIFAR10IfNotPresent(from location: URL, to directory: URL) {\n",
    "    let downloadPath = directory.appendingPathComponent(\"cifar-10-batches-bin\").path\n",
    "    let directoryExists = FileManager.default.fileExists(atPath: downloadPath)\n",
    "    let contentsOfDir = try? FileManager.default.contentsOfDirectory(atPath: downloadPath)\n",
    "    let directoryEmpty = (contentsOfDir == nil) || (contentsOfDir!.isEmpty)\n",
    "\n",
    "    guard !directoryExists || directoryEmpty else { return }\n",
    "\n",
    "    let _ = DatasetUtilities.downloadResource(\n",
    "        filename: \"cifar-10-binary\", fileExtension: \"tar.gz\",\n",
    "        remoteRoot: location.deletingLastPathComponent(), localStorageDirectory: directory)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct Img2Label: ImageClassificationDataset {\n",
    "    public typealias SourceDataSet = [TensorPair<Float, Int32>]\n",
    "    public let training: Batcher<SourceDataSet>\n",
    "    public let test: Batcher<SourceDataSet>\n",
    "\n",
    "    public init(batchSize: Int) {\n",
    "        self.init(\n",
    "            batchSize: batchSize,\n",
    "            remoteBinaryArchiveLocation: URL(\n",
    "                string: \"https://storage.googleapis.com/s4tf-hosted-binaries/datasets/CIFAR10/cifar-10-binary.tar.gz\")!, \n",
    "            normalizing: true)\n",
    "    }\n",
    "\n",
    "    public init(\n",
    "        batchSize: Int,\n",
    "        remoteBinaryArchiveLocation: URL, \n",
    "        localStorageDirectory: URL = DatasetUtilities.defaultDirectory\n",
    "                .appendingPathComponent(\"CIFAR10\", isDirectory: true), \n",
    "        normalizing: Bool) \n",
    "    {\n",
    "        downloadCIFAR10IfNotPresent(from: remoteBinaryArchiveLocation, to: localStorageDirectory)\n",
    "        self.training = Batcher(\n",
    "            on: loadCIFARTrainingFiles(localStorageDirectory: localStorageDirectory, normalizing: normalizing),\n",
    "            batchSize: batchSize,\n",
    "            numWorkers: 1, //No need to use parallelism since everything is loaded in memory\n",
    "            shuffle: true)\n",
    "        self.test = Batcher(\n",
    "            on: loadCIFARTestFile(localStorageDirectory: localStorageDirectory, normalizing: normalizing),\n",
    "            batchSize: batchSize,\n",
    "            numWorkers: 1) //No need to use parallelism since everything is loaded in memory\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "dataset.training.count: 40\n"
     ]
    }
   ],
   "source": [
    "let batchSize = 25\n",
    "\n",
    "let dataset = Img2Label(batchSize: batchSize)\n",
    "print(\"dataset.training.count: \\(dataset.training.count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
